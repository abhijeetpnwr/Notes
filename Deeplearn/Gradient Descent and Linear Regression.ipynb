{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent:\n",
    "\n",
    "Gradient descent is one of those “greatest hits” algorithms that can offer a new perspective for solving problems. \n",
    "\n",
    "At a theoretical level, gradient descent is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function(# Notes). This iterative minimization is achieved using calculus, taking steps in the negative direction of the function gradient.This iterative minimization is achieved using calculus, taking steps in the negative direction of the function gradient.\n",
    "\n",
    "It’s sometimes difficult to see how this mathematical explanation translates into a practical setting, so it’s helpful to look at an example. The canonical example when explaining gradient descent is linear regression.\n",
    "\n",
    "\n",
    "Code for this can be found at: [Githubcode](https://github.com/mattnedrich/GradientDescentExample)\n",
    "\n",
    "**In Layman's terms:**\n",
    "\n",
    "assume you are at the top of a mountain. And you are blind. Your aim is to arrive the piedmont to below as quickly as possible.\n",
    "\n",
    "![Mountain](https://qph.ec.quoracdn.net/main-qimg-c2f0febd264b56ca142c8e897003a018-c)\n",
    "\n",
    "You also do not know the structure of the mountain side as well thus most reasonable choice is to choose steepest descent to go down but as I said you are blind so no structural information in advance.You need a some kind of heuristic to find the correct way. One of the best choice and the simplest one is to check the decline rate by single step for each possible direction and choose the most steepest one. Gradient of a function also gives the this heuristic information to algorithm when we think the function as a mountain landscape that we try to find the lowest part as the minimum of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression :\n",
    "    \n",
    "Simply stated, the goal of linear regression is to fit a line to a set of points. Consider the following data.\n",
    "![Linear Regression](https://spin.atomicobject.com/wp-content/uploads/points_for_linear_regression1.png)\n",
    "\n",
    "Let’s suppose we want to model the above set of points with a line. To do this we’ll use the standard(#-Notes) y = mx + b \n",
    "line equation where m is the line’s slope and b is the line’s y-intercept. To find the best line for our data, we need to find the best set of slope m and y-intercept b values.\n",
    "\n",
    "Let’s suppose we want to model the above set of points with a line. To do this we’ll use the standard y = mx + b line equation where m is the line’s slope and b is the line’s y-intercept. To find the best line for our data, we need to find the best set of slope m and y-intercept b values.\n",
    "\n",
    "A standard approach to solving this type of problem is to define an error function (also called a cost function) that measures how “good” a given line is. This function will take in a (m,b) pair and return an error value based on how well the line fits our data. To compute this error for a given line, we’ll iterate through each (x,y) point in our data set and sum the square distances between each point’s y value and the candidate line’s y value (computed at mx + b). It’s conventional to square this distance to ensure that it is positive and to make our error function differentiable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In python code will look something like:\n",
    "    \n",
    "    # y = mx + b\n",
    "# m is slope, b is y-intercept\n",
    "def computeErrorForLineGivenPoints(b, m, points):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        #if x is same for both , then distance is y2-y1 straight .  To prevent we take square of it.\n",
    "        \n",
    "        totalError += (points[i].y - (m * points[i].x + b)) ** 2\n",
    "    return totalError / float(len(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines that fit our data better (where better is defined by our error function) will result in lower error values. If we minimize this function, we will get the best line for our data. Since our error function consists of two parameters (m and b) we can visualize it as a two-dimensional surface. This is what it looks like for our data set:\n",
    "\n",
    "![Dataset view](https://spin.atomicobject.com/wp-content/uploads/gradient_descent_error_surface.png)\n",
    "\n",
    "Each point in this two-dimensional space represents a line. The height of the function at each point is the error value for that line. You can see that some lines yield smaller error values than others (i.e., fit our data better). When we run gradient descent search, we will start from some location on this surface and move downhill to find the line with the lowest error.\n",
    "\n",
    "To run gradient descent on this error function, we first need to compute its gradient. The gradient will act like a compass and always point us downhill. To compute it, we will need to differentiate our error function. \n",
    "\n",
    "So we will keep looking for right m and b values .REsults into somethign like this:\n",
    "\n",
    "![Image](https://spin.atomicobject.com/wp-content/uploads/gradient_descent_search1.png)\n",
    "\n",
    "For more detailed analysis with code read [this](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)\n",
    "\n",
    "\n",
    "Watch video on youtube :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB//9k=\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/JuAJd9Qvs6U\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f08f4580828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "# Youtube\n",
    "YouTubeVideo('JuAJd9Qvs6U')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:  \n",
    "\n",
    "\n",
    "\n",
    "**1.Minimizing a function**: Minimizing a function f(x) is finding the value x for which f(x) is the lowest.we are looking for the optimal values to represent a line which goes the nearest possible between the values\n",
    "    so in the notation used here the thetas are the coefficients in some polynomial function. That's what we're trying to find. So our job is to find the least-wrong set of thetas. To do that, we make a function that gives us the wrongness of a particular set of thetas against our training data. It's called the cost function, which is kind of a crappy name in this context.So the job of the learning algorithm is to find those thetas that give you the least error, or in other words that minimize the cost function. This is useful because minimization is a problem we know how to solve in lots of different ways. The class has told us about two of them so far.\n",
    "\n",
    "\n",
    "**2.Line Equation:**\n",
    "![line](Images/lineeq.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details about  understanding equation at [this page](https://www.mathsisfun.com/algebra/linear-equations.html)\n",
    "\n",
    "You can play with linear equation at [this example](https://www.mathsisfun.com/data/straight_line_graph.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
