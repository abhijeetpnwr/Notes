{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difference between logistic regression vs linear regression:**\n",
    "\n",
    "***Question*** : When we have to predict the value of a categorical outcome, we use logistic regression. I believe    we use linear regression to also predict the value of an outcome given the input values.\n",
    "\n",
    "Then, what is the difference between the two methodologies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:In linear regression, the outcome (dependent variable) is continuous. It can have any one of an infinite number of possible values. In logistic regression, the outcome (dependent variable) has only a limited number of possible values.\n",
    "\n",
    "For instance, if X contains the area in square feet of houses, and Y contains the corresponding sale price of those houses, you could use linear regression to predict selling price as a function of house size. While the possible selling price may not actually be any, there are so many possible values that a linear regression model would be chosen.\n",
    "\n",
    "If, instead, you wanted to predict, based on size, whether a house would sell for more than \\$200K, you would use logistic regression. The possible outputs are either Yes, the house will sell for more than \\$200K, or No, the house will not.\n",
    "\n",
    "(The above examples inspired/stolen from my recollection of Andrew Ng's machine learning videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer2**:\n",
    "\n",
    "Linear regression vs output as probabilities\n",
    "\n",
    "It's tempting to use the linear regression output as probabilities but it's a mistake because the output can be negative, and greater than 1 whereas probability can not. As regression might actually produce probabilities that could be less than 0, or even bigger than 1, logistic regression was introduced. \n",
    "\n",
    "Source: http://gerardnico.com/wiki/data_mining/simple_logistic_regression\n",
    "\n",
    "![Linear regression vs linear regression](https://i.stack.imgur.com/rhVmk.jpg)\n",
    "\n",
    "In linear regression, the outcome (dependent variable) is continuous. It can have any one of an infinite number of possible values. In logistic regression, the outcome (dependent variable) has only a limited number of possible values.\n",
    "The dependent variable\n",
    "\n",
    "Logistic Regression is used when response variable is categorical in nature. For instance, Yes/No, True/False, Red/Green/Blue, 1st/2nd/3rd/4th etc. Linear Regression is used when your response variable is continuous. For instance Weight, Height, Number of hours etc.\n",
    "Equation\n",
    "\n",
    "Linear Regression gives an equation which is of the form Y = mX + C, means equation with degree 1.However, Logistic Regression gives an equation which is of the form Y = e^X/1 + e^-X\n",
    "Coefficient interpretation\n",
    "\n",
    "In linear regression, the coefficient interpretation of independent variables are quite straight forward (i.e. holding all other variables constant, with an unit increase in this variable, the dependent variable is expected to increase/decrease by xxx). However in logistic regression, depends on the family (binomial, poisson, etc.) and link (log, logit, inverse-log, etc.) you use, the interpretation is different.\n",
    "Error Minimization Technique\n",
    "\n",
    "Linear Regression uses Ordinary Least Squares method to minimise the errors and arrive at a best possible fit while Logistic regression uses maximum likelihood method to arrive at the solution.\n",
    "\n",
    "Linear regression is usually solved by minimizing the least squares error of the model to the data, therefore large errors are penalized quadratically. Logistic regression is just the opposite. Using the logistic loss function causes large errors to be penalized to an asymptotically constant.\n",
    "\n",
    "Consider linear regression on a categorical {0,1} outcomes to see why this is a problem. If your model predicts the outcome is 38 when truth is 1, you've lost nothing. Linear regression would try to reduce that 38, logistic wouldn't (as much) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
